{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52180fbe",
   "metadata": {},
   "source": [
    "# Notebook Avançado: Ciência de Dados com IA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f5e10",
   "metadata": {},
   "source": [
    "\n",
    "## Objetivo\n",
    "Neste notebook, iremos:\n",
    "1. Recuperar o dataset processado armazenado no MLflow.\n",
    "2. Comparar múltiplos algoritmos de machine learning.\n",
    "3. Armazenar e versionar no MLflow o modelo com melhor desempenho e menor custo computacional.\n",
    "\n",
    "## Bibliotecas Necessárias\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manipulação e visualização de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Bibliotecas para aprendizado de máquina\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# MLflow para gerenciamento de experimentos\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Supressão de avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a22a29",
   "metadata": {},
   "source": [
    "## Recuperando o Dataset do MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Especificar o caminho do artefato no MLflow\n",
    "artifact_path = \"dados_processados.csv\"\n",
    "\n",
    "# Baixar o artefato do MLflow\n",
    "downloaded_artifact = mlflow.artifacts.download_artifacts(artifact_path)\n",
    "print(f\"Artefato baixado com sucesso em: {downloaded_artifact}\")\n",
    "\n",
    "# Carregar o dataset processado\n",
    "dados = pd.read_csv(downloaded_artifact)\n",
    "dados.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c9071",
   "metadata": {},
   "source": [
    "## Dividindo os Dados para Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b983cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separando as features (X) e o target (y)\n",
    "X = dados.drop(columns=[\"Survived\"], errors='ignore')  # Substitua 'Survived' pelo nome da coluna alvo, se necessário\n",
    "y = dados[\"Survived\"]  # Substitua 'Survived' pelo nome da coluna alvo, se necessário\n",
    "\n",
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Conjunto de treinamento: {X_train.shape}\")\n",
    "print(f\"Conjunto de teste: {X_test.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6afdbd",
   "metadata": {},
   "source": [
    "## Comparando Algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ed8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lista de modelos para comparar\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "# Avaliar cada modelo\n",
    "for nome, modelo in modelos.items():\n",
    "    inicio = time.time()\n",
    "    modelo.fit(X_train, y_train)  # Treinamento\n",
    "    fim = time.time()\n",
    "    \n",
    "    # Previsões\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Métricas\n",
    "    acuracia = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    tempo_treino = fim - inicio\n",
    "    \n",
    "    # Registrar no MLflow\n",
    "    with mlflow.start_run(run_name=nome):\n",
    "        mlflow.log_param(\"Modelo\", nome)\n",
    "        mlflow.log_metric(\"Acurácia\", acuracia)\n",
    "        mlflow.log_metric(\"F1-Score\", f1)\n",
    "        mlflow.log_metric(\"Tempo de Treinamento\", tempo_treino)\n",
    "        mlflow.sklearn.log_model(modelo, \"modelo\")\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    resultados.append({\n",
    "        \"Modelo\": nome,\n",
    "        \"Acurácia\": acuracia,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Tempo de Treinamento (s)\": tempo_treino\n",
    "    })\n",
    "    print(f\"Modelo {nome} treinado e registrado no MLflow.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb612a5",
   "metadata": {},
   "source": [
    "## Resultados da Comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e638c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.sort_values(by=[\"Acurácia\", \"Tempo de Treinamento (s)\"], ascending=[False, True], inplace=True)\n",
    "print(\"Resultados da Comparação:\")\n",
    "print(df_resultados)\n",
    "\n",
    "# Exibir o modelo com melhor desempenho\n",
    "melhor_modelo = df_resultados.iloc[0]\n",
    "print(f\"Melhor Modelo: {melhor_modelo['Modelo']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61670150",
   "metadata": {},
   "source": [
    "## Armazenando o Melhor Modelo no MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recuperar o modelo com melhor desempenho\n",
    "nome_melhor_modelo = melhor_modelo[\"Modelo\"]\n",
    "modelo_final = modelos[nome_melhor_modelo]\n",
    "\n",
    "# Armazenar o modelo final no MLflow\n",
    "with mlflow.start_run(run_name=\"Melhor Modelo\"):\n",
    "    mlflow.log_param(\"Modelo\", nome_melhor_modelo)\n",
    "    mlflow.log_metric(\"Acurácia\", melhor_modelo[\"Acurácia\"])\n",
    "    mlflow.log_metric(\"F1-Score\", melhor_modelo[\"F1-Score\"])\n",
    "    mlflow.log_metric(\"Tempo de Treinamento\", melhor_modelo[\"Tempo de Treinamento (s)\"])\n",
    "    mlflow.sklearn.log_model(modelo_final, \"melhor_modelo\")\n",
    "print(f\"Melhor modelo ({nome_melhor_modelo}) armazenado com sucesso no MLflow.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8122e5",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c3534",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook demonstrou como comparar múltiplos algoritmos de machine learning, avaliar seus desempenhos e armazenar o melhor modelo no MLflow.\n",
    "O MLflow foi utilizado para rastrear e versionar os experimentos e os modelos de forma eficaz.\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
