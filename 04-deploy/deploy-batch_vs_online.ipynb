{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fbd79dc7",
      "metadata": {
        "id": "fbd79dc7"
      },
      "source": [
        "# Deploy e Serving de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26cec9e3",
      "metadata": {
        "id": "26cec9e3"
      },
      "source": [
        "\n",
        "## Objetivo\n",
        "1. Realizar deploy local do modelo para servir predições.\n",
        "2. Executar inferências online e em batch.\n",
        "3. Comparar o tempo de resposta e o uso de memória para as inferências.\n",
        "\n",
        "⚠️ **ATENÇÃO: ME EXECUTE NO COLAB COM GPU OU LOCALMENTE COM GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "llIRkJBq1bZJ",
      "metadata": {
        "id": "llIRkJBq1bZJ"
      },
      "outputs": [],
      "source": [
        "# Esse comando pode demorar um pouco para rodar, mas é só na primeira vez ;)\n",
        "!pip install -q transformers==4.50.3 pandas==2.2.2 torch==2.6.0\\\n",
        " datasets==3.5.0 pillow==11.1.0 --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ub4WCvMb3OgA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub4WCvMb3OgA",
        "outputId": "90e50cc7-a533-423c-dd48-b60944d05679"
      },
      "outputs": [],
      "source": [
        "# Verificando as configs da GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4983bb",
      "metadata": {
        "id": "7e4983bb"
      },
      "outputs": [],
      "source": [
        "# Manipulação e visualização de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Importando modelo de classificação para imagens\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dPO-12s3T0j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dPO-12s3T0j",
        "outputId": "3a7d0763-d445-44f1-fb35-692bcc5eecc3"
      },
      "outputs": [],
      "source": [
        "# prompt: Get GPU using cuda for pytorch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ebee7d",
      "metadata": {
        "id": "a3ebee7d"
      },
      "source": [
        "## Baixando a modelo e dados para o nosso experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e537d82",
      "metadata": {
        "id": "9e537d82"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"huggingface/cats-image\")\n",
        "amostra = dataset[\"test\"][\"image\"][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d9cec4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "7d9cec4c",
        "outputId": "be745fc7-60cc-4859-c7b7-73505c49d1fb"
      },
      "outputs": [],
      "source": [
        "amostra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8a8ac9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8a8ac9e",
        "outputId": "58a14aae-1228-41e3-88c8-f1853442a573"
      },
      "outputs": [],
      "source": [
        "# Paper: https://paperswithcode.com/method/resnet\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
        "\n",
        "inputs = image_processor(amostra, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041a16f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "041a16f5",
        "outputId": "edc38146-a300-491f-be4f-8b7becce35c7"
      },
      "outputs": [],
      "source": [
        "predicted_label = logits.argmax(-1).item()\n",
        "model.config.id2label[predicted_label]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea302869",
      "metadata": {
        "id": "ea302869"
      },
      "source": [
        "### Baixando um dataset um pouco maior e testando mais uma predição"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "357d4664",
      "metadata": {
        "id": "357d4664"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"microsoft/cats_vs_dogs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pT4AFTEp2Pao",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "pT4AFTEp2Pao",
        "outputId": "6ad72f06-c3b5-4eba-ed79-5b8659c133dd"
      },
      "outputs": [],
      "source": [
        "amostra = dataset[\"train\"][-1][\"image\"]\n",
        "amostra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g5p0wSJd3hhk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g5p0wSJd3hhk",
        "outputId": "a1e325f0-942a-47c0-ba55-28b594fb2ae5"
      },
      "outputs": [],
      "source": [
        "inputs = image_processor(amostra, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "model.config.id2label[predicted_label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JElHar7s3obW",
      "metadata": {
        "id": "JElHar7s3obW"
      },
      "outputs": [],
      "source": [
        "# Movendo o modelo para a GPU\n",
        "_ = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "394f6b89",
      "metadata": {
        "id": "394f6b89"
      },
      "source": [
        "## Realizando o Deploy Local do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990e2cce",
      "metadata": {
        "id": "990e2cce"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 1_000\n",
        "\n",
        "# Selecionando algumas amostras\n",
        "dados_teste = dataset[\"train\"][:N_SAMPLES][\"image\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2e5e51a",
      "metadata": {
        "id": "d2e5e51a"
      },
      "source": [
        "### Inferência em Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3972da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3972da1",
        "outputId": "1454d36c-9982-4344-dbdb-2c726c3dc906"
      },
      "outputs": [],
      "source": [
        "# Medir o tempo de inferência em batch\n",
        "inputs = image_processor(dados_teste, return_tensors=\"pt\")\n",
        "print(f'Shape inputs: {inputs[\"pixel_values\"].shape}')\n",
        "inicio_batch = time.time()\n",
        "with torch.no_grad():\n",
        "    predictions = model(**inputs.to(device))\n",
        "predicted_labels = predictions.logits.cpu().argmax(-1).numpy()\n",
        "fim_batch = time.time()\n",
        "\n",
        "tempo_batch = fim_batch - inicio_batch\n",
        "print(f\"Resultado predição: {predicted_labels.shape}\")\n",
        "print(f\"Tempo de inferência em batch: {tempo_batch:.4f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15450b4b",
      "metadata": {
        "id": "15450b4b"
      },
      "source": [
        "### Inferência Online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fad71e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fad71e2",
        "outputId": "f5934ab4-7583-4ae0-b452-9f7739e1ab66"
      },
      "outputs": [],
      "source": [
        "# Medir o tempo de inferência online\n",
        "tempos_online = []\n",
        "\n",
        "sample = image_processor(dados_teste[0:1], return_tensors=\"pt\")\n",
        "print(f'Shape inputs: {sample[\"pixel_values\"].shape}')\n",
        "\n",
        "for i in range(N_SAMPLES):  # Inferência para N amostras\n",
        "    inicio_online = time.time()\n",
        "    inputs = image_processor(dados_teste[i:i+1], return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(**inputs)\n",
        "    predicted_labels = predictions.logits.cpu().argmax(-1).numpy()\n",
        "    fim_online = time.time()\n",
        "    tempos_online.append(fim_online - inicio_online)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F-2EylO6_xFc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "F-2EylO6_xFc",
        "outputId": "60fd4e8c-ce30-4b4e-ef1e-f7680d3a8d5c"
      },
      "outputs": [],
      "source": [
        "series = pd.Series(tempos_online)\n",
        "series.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nwMl-1YFC33u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwMl-1YFC33u",
        "outputId": "a97cdb7e-7371-4f52-a378-7e5d1012f378"
      },
      "outputs": [],
      "source": [
        "series.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sFR5O9YnCRoj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "sFR5O9YnCRoj",
        "outputId": "163f0f64-4b1b-49bc-eabe-569a8ccbe3bd"
      },
      "outputs": [],
      "source": [
        "series.hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FmuTEUxu6A-6",
      "metadata": {
        "id": "FmuTEUxu6A-6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
