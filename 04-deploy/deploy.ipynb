{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd79dc7",
   "metadata": {},
   "source": [
    "# Deploy e Serving de Modelos com MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cec9e3",
   "metadata": {},
   "source": [
    "\n",
    "## Objetivo\n",
    "1. Recuperar o melhor modelo armazenado no MLflow.\n",
    "2. Realizar deploy local do modelo para servir previsões.\n",
    "3. Executar inferências online e em batch.\n",
    "4. Comparar o tempo de resposta e o uso de memória para as inferências.\n",
    "\n",
    "## Bibliotecas Necessárias\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4983bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manipulação e visualização de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# MLflow para gerenciamento de modelos e deploy\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebee7d",
   "metadata": {},
   "source": [
    "## Recuperando o Melhor Modelo do MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e537d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recuperar o ID do experimento e a execução mais recente com o melhor modelo\n",
    "experiment_name = \"Melhor Modelo\"  # Nome definido anteriormente\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Recuperar a última execução do experimento\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "if experiment:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    runs = client.search_runs(experiment_id, order_by=[\"metrics.Acurácia DESC\"], max_results=1)\n",
    "    best_run = runs[0]\n",
    "    model_uri = f\"runs:/{best_run.info.run_id}/melhor_modelo\"\n",
    "    print(f\"Melhor modelo encontrado no URI: {model_uri}\")\n",
    "else:\n",
    "    raise ValueError(\"Experimento não encontrado no MLflow.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f6b89",
   "metadata": {},
   "source": [
    "## Realizando o Deploy Local do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carregar o modelo\n",
    "modelo = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Testar o modelo carregado com um exemplo\n",
    "dados_teste = X_test[:5]  # Substitua por amostras reais se necessário\n",
    "predicoes_teste = modelo.predict(dados_teste)\n",
    "print(f\"Previsões do modelo: {predicoes_teste}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e5e51a",
   "metadata": {},
   "source": [
    "## Inferência em Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3972da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Medir o tempo de inferência em batch\n",
    "inicio_batch = time.time()\n",
    "predicoes_batch = modelo.predict(X_test)  # Inferência em todo o conjunto de teste\n",
    "fim_batch = time.time()\n",
    "\n",
    "tempo_batch = fim_batch - inicio_batch\n",
    "print(f\"Tempo de inferência em batch: {tempo_batch:.4f} segundos\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15450b4b",
   "metadata": {},
   "source": [
    "## Inferência Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Medir o tempo de inferência online\n",
    "tempos_online = []\n",
    "for i in range(10):  # Inferência para 10 amostras\n",
    "    inicio_online = time.time()\n",
    "    modelo.predict(X_test.iloc[i:i+1])\n",
    "    fim_online = time.time()\n",
    "    tempos_online.append(fim_online - inicio_online)\n",
    "\n",
    "tempo_medio_online = np.mean(tempos_online)\n",
    "print(f\"Tempo médio de inferência online: {tempo_medio_online:.4f} segundos\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f7bef4",
   "metadata": {},
   "source": [
    "## Comparação de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparar tempos de inferência\n",
    "print(f\"Tempo de inferência em batch: {tempo_batch:.4f} segundos\")\n",
    "print(f\"Tempo médio de inferência online: {tempo_medio_online:.4f} segundos\")\n",
    "\n",
    "# Uso de memória\n",
    "memoria_inicial = psutil.virtual_memory().used / 1e6  # Memória inicial em MB\n",
    "modelo.predict(X_test)  # Inferência para medir uso de memória\n",
    "memoria_final = psutil.virtual_memory().used / 1e6  # Memória final em MB\n",
    "\n",
    "uso_memoria = memoria_final - memoria_inicial\n",
    "print(f\"Uso de memória para inferência: {uso_memoria:.2f} MB\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12579ecb",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e065815",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook demonstrou como realizar o deploy de um modelo armazenado no MLflow, executar inferências online e em batch, e comparar o desempenho em termos de tempo e uso de memória.\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
